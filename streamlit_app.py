import streamlit as st
import cv2
import numpy as np
import tempfile
import time
from collections import deque

# =========================
# Streamlitè¨­å®š
# =========================
st.set_page_config(page_title="è»¢å€’æ¤œçŸ¥ï¼ˆæ­©è¡Œå¯¾å¿œï¼‰", layout="wide")
st.title("ğŸ“¹ è»¢å€’æ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ ï¼ˆå¹³é¢ãƒ»å¤©äº•ãƒ»æ­©è¡Œå¯¾å¿œï¼‰")

st.markdown("""
### åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ï¼ˆå®Ÿé‹ç”¨ãƒ¬ãƒ™ãƒ«ï¼‰
1. **ç§»å‹•é‡ï¼ˆé€Ÿåº¦ï¼‰ã‚’å¸¸æ™‚è¨ˆæ¸¬**
2. **æ€¥æ¸›é€Ÿã‚’è»¢å€’ãƒˆãƒªã‚¬ãƒ¼** ã¨ã™ã‚‹
3. **ä½ç§»å‹•çŠ¶æ…‹ãŒç¶™ç¶š** â†’ è»¢å€’ç¢ºå®š
""")

uploaded_file = st.file_uploader(
    "å¤©äº•ã‚«ãƒ¡ãƒ©ã®å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
    type=["mp4", "avi", "mov"]
)

# =========================
# äººæ¤œå‡ºï¼ˆHOGï¼‰
# =========================
hog = cv2.HOGDescriptor()
hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())

frame_area = st.image([])
status_area = st.empty()

# =========================
# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆé‡è¦ï¼‰
# =========================
LOW_MOVE_THRESHOLD = 8        # ã»ã¼æ­¢ã¾ã£ã¦ã„ã‚‹
HIGH_MOVE_THRESHOLD = 25     # æ­©è¡Œ
DECEL_THRESHOLD = 15         # æ€¥æ¸›é€Ÿ
CONFIRM_TIME = 2.5           # ç§’

speed_history = deque(maxlen=5)

prev_center = None
fall_trigger_time = None
fallen = False

# =========================
# å‹•ç”»å‡¦ç†
# =========================
if uploaded_file is not None:
    tfile = tempfile.NamedTemporaryFile(delete=False)
    tfile.write(uploaded_file.read())

    cap = cv2.VideoCapture(tfile.name)

    if not cap.isOpened():
        st.error("å‹•ç”»ã‚’é–‹ã‘ã¾ã›ã‚“")
        st.stop()

    st.success("è§£æã‚’é–‹å§‹ã—ã¾ã™")

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        frame = cv2.resize(frame, (640, 360))

        boxes, _ = hog.detectMultiScale(
            frame,
            winStride=(8, 8),
            padding=(8, 8),
            scale=1.05
        )

        current_center = None

        if len(boxes) > 0:
            x, y, w, h = boxes[0]
            current_center = (x + w // 2, y + h // 2)

            cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 255, 0), 2)
            cv2.circle(frame, current_center, 5, (0, 0, 255), -1)

        # ===== é€Ÿåº¦è¨ˆç®— =====
        speed = 0
        if prev_center and current_center:
            speed = np.linalg.norm(
                np.array(current_center) - np.array(prev_center)
            )

        speed_history.append(speed)
        avg_speed = np.mean(speed_history) if speed_history else 0

        # ===== è»¢å€’ãƒˆãƒªã‚¬ãƒ¼ï¼ˆæ€¥æ¸›é€Ÿï¼‰=====
        if avg_speed > HIGH_MOVE_THRESHOLD:
            walking = True
        else:
            walking = False

        if walking and avg_speed < DECEL_THRESHOLD:
            fall_trigger_time = time.time()

        # ===== è»¢å€’ç¢ºå®šåˆ¤å®š =====
        if fall_trigger_time:
            if avg_speed < LOW_MOVE_THRESHOLD:
                if time.time() - fall_trigger_time > CONFIRM_TIME:
                    fallen = True
            else:
                # å†ã³æ­©ã„ãŸã‚‰ãƒªã‚»ãƒƒãƒˆ
                fall_trigger_time = None
                fallen = False

        # ===== è¡¨ç¤º =====
        if fallen:
            status_area.error("âš ï¸ æ­©è¡Œä¸­ã®è»¢å€’ã‚’æ¤œçŸ¥ã—ã¾ã—ãŸ")
        else:
            status_area.success("âœ… æ­£å¸¸")

        prev_center = current_center
        frame_area.image(frame, channels="BGR")

    cap.release()
    st.info("è§£æçµ‚äº†")

else:
    st.info("å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
